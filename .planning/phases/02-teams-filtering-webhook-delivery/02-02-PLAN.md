---
phase: 02-teams-filtering-webhook-delivery
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified: [nchook.py]
autonomous: true

must_haves:
  truths:
    - "Each notification that passes filtering is POSTed as JSON to the configured webhook URL"
    - "JSON payload contains senderName, chatId, content, timestamp, type, subtitle, _source, _truncated"
    - "Webhook failures (timeout, HTTP error, connection refused) are logged and skipped without crashing"
    - "The event loop uses config values for poll_interval and webhook_timeout"
    - "Startup summary shows webhook URL and watched bundle IDs"
    - "Subtitle (subt) field is included in the webhook payload"
    - "Notifications that fail the filter are logged at DEBUG level and skipped"
  artifacts:
    - path: "nchook.py"
      provides: "Webhook payload construction"
      contains: "def build_webhook_payload"
    - path: "nchook.py"
      provides: "HTTP POST with log-and-skip error handling"
      contains: "def post_webhook"
    - path: "nchook.py"
      provides: "Modified event loop with filter-classify-build-post pipeline"
      contains: "passes_filter"
    - path: "nchook.py"
      provides: "Modified main() loading config before event loop"
      contains: "load_config"
  key_links:
    - from: "run_watcher()"
      to: "passes_filter()"
      via: "filter check before webhook delivery in notification processing loop"
      pattern: "passes_filter\\(notif"
    - from: "run_watcher()"
      to: "post_webhook()"
      via: "POST after building payload for each passing notification"
      pattern: "post_webhook\\(payload"
    - from: "main()"
      to: "load_config()"
      via: "config loaded at startup before entering event loop"
      pattern: "config\\s*=\\s*load_config"
    - from: "main()"
      to: "run_watcher()"
      via: "config dict passed to run_watcher"
      pattern: "run_watcher\\(.*config"
    - from: "build_webhook_payload()"
      to: "detect_truncation()"
      via: "truncation flag set in payload"
      pattern: "detect_truncation"
---

<objective>
Add webhook delivery (build_webhook_payload, post_webhook) and wire the complete pipeline into the event loop: main() loads config, run_watcher() filters notifications through the pipeline, builds JSON payloads, and POSTs to the webhook. Update startup summary to include webhook URL and bundle IDs.

Purpose: This completes the Phase 2 data pipeline. After this plan, the daemon is a working Teams notification interceptor that filters, formats, and delivers notifications to a webhook.
Output: nchook.py with complete end-to-end pipeline: config -> watch -> filter -> classify -> build payload -> POST webhook.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-teams-filtering-webhook-delivery/02-RESEARCH.md
@.planning/phases/02-teams-filtering-webhook-delivery/02-01-SUMMARY.md
@nchook.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add webhook delivery functions to nchook.py</name>
  <files>nchook.py</files>
  <action>
Add two new functions to nchook.py in a new section "Webhook Delivery" placed AFTER the "Teams Filtering" section and BEFORE the "kqueue WAL Watcher" section.

**New function: `build_webhook_payload(notif, msg_type)`** (WEBH-02, DBWT-06):
- Format timestamp: if `notif.get("timestamp", 0) > 0`, format as ISO 8601 UTC string using `time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(ts))`. Otherwise set to None.
- Return dict with these exact keys:
  - `"senderName"`: `notif.get("title", "")`
  - `"chatId"`: `notif.get("subtitle", "")` -- subtitle serves as chat/channel identifier
  - `"content"`: `notif.get("body", "")`
  - `"timestamp"`: the formatted ISO string or None
  - `"type"`: msg_type parameter (from classify_notification)
  - `"subtitle"`: `notif.get("subtitle", "")` -- explicit pass-through per DBWT-06
  - `"_source"`: `"macos-notification-center"` (static metadata)
  - `"_truncated"`: result of `detect_truncation(notif.get("body", ""))`
- NOTE: The requirement lists "senderId" but macOS notifications only provide display names, not Azure AD user IDs. Omit senderId per research recommendation (PROJECT.md documents this as a known limitation).

**New function: `post_webhook(payload, webhook_url, timeout=10)`** (WEBH-01, WEBH-03):
- Serialize payload with `json.dumps(payload).encode("utf-8")`
- Create `urllib.request.Request` with URL=webhook_url, data=serialized, headers={"Content-Type": "application/json"}, method="POST"
- Call `urllib.request.urlopen(req, timeout=timeout)` inside try block
- On success: `logging.info("Webhook delivered: HTTP %d (%d bytes sent)", resp.status, len(data))`; return True
- Exception handling (catch in THIS ORDER -- hierarchy matters):
  1. `urllib.error.HTTPError as e`: log `"Webhook HTTP error: %d %s (url=%s)"` with e.code, e.reason, webhook_url
  2. `urllib.error.URLError as e`: log `"Webhook connection error: %s (url=%s)"` with e.reason, webhook_url
  3. `TimeoutError`: log `"Webhook timed out after %ds (url=%s)"` with timeout, webhook_url
  4. `Exception as e`: log `"Webhook unexpected error: %s (url=%s)"` with str(e), webhook_url
- All exception handlers return False. NEVER re-raise. NEVER crash. Log-and-skip per WEBH-03.
  </action>
  <verify>
```bash
python3 -c "
from nchook import build_webhook_payload, post_webhook

# Payload construction
notif = {
    'title': 'John Smith',
    'subtitle': 'General',
    'body': 'Hello team',
    'timestamp': 1707667200,  # some Unix timestamp
    'app': 'com.microsoft.teams2',
    'rec_id': 42,
}
payload = build_webhook_payload(notif, 'channel_message')

# Verify all required fields present
assert 'senderName' in payload and payload['senderName'] == 'John Smith'
assert 'chatId' in payload and payload['chatId'] == 'General'
assert 'content' in payload and payload['content'] == 'Hello team'
assert 'timestamp' in payload and payload['timestamp'] is not None
assert 'type' in payload and payload['type'] == 'channel_message'
assert 'subtitle' in payload and payload['subtitle'] == 'General'
assert '_source' in payload and payload['_source'] == 'macos-notification-center'
assert '_truncated' in payload and payload['_truncated'] == False

# Verify truncation flag on long body
long_notif = dict(notif)
long_notif['body'] = 'x' * 200
long_payload = build_webhook_payload(long_notif, 'direct_message')
assert long_payload['_truncated'] == True

# Verify post_webhook handles bad URL gracefully (no crash)
result = post_webhook({'test': True}, 'http://localhost:99999/nonexistent', timeout=2)
assert result == False  # Should fail but not crash

print('All webhook function tests passed.')
"
```
  </verify>
  <done>
build_webhook_payload returns a dict with all 8 required fields including subtitle (DBWT-06) and _truncated (WEBH-04). post_webhook POSTs JSON and returns True/False, catching all urllib exceptions without crashing.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire pipeline into event loop and startup</name>
  <files>nchook.py</files>
  <action>
Modify three existing functions in nchook.py to integrate the filter-classify-build-post pipeline.

**Modify `print_startup_summary(db_path, last_rec_id, config=None)`:**
- Add optional `config` parameter (default None for backward compatibility, though Phase 1 code path no longer calls this directly).
- After existing log lines (DB path, FDA status, Last rec_id), add:
  - If config is not None:
    - `logging.info("  Webhook URL: %s", config.get("webhook_url", "NOT SET"))`
    - `logging.info("  Bundle IDs:  %s", ", ".join(sorted(config.get("bundle_ids", []))))`
    - `logging.info("  Poll interval: %.1fs", config.get("poll_interval", POLL_FALLBACK_SECONDS))`
    - `logging.info("  Log level:   %s", config.get("log_level", "INFO"))`

**Modify `run_watcher(db_path, wal_path, state_path, config=None)`:**
- Add `config` parameter.
- Use `config.get("poll_interval", POLL_FALLBACK_SECONDS)` instead of `POLL_FALLBACK_SECONDS` for the kqueue timeout and the fallback sleep. Store in a local variable `poll_interval` at the top.
- Pass config to `print_startup_summary(db_path, last_rec_id, config)`.
- REPLACE the notification processing block (the `for notif in notifications:` loop that currently just logs) with the pipeline:
  ```python
  for notif in notifications:
      if config is not None and not passes_filter(notif, config):
          logging.debug(
              "Filtered: app=%s title=%s body=%.50s",
              notif["app"], notif["title"], notif.get("body", ""),
          )
          continue

      # Log the notification (keep Phase 1 behavior for non-config mode)
      if notif["timestamp"] > 0:
          ts_str = time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime(notif["timestamp"]))
      else:
          ts_str = "unknown"
      logging.info(
          "Notification | app=%s | title=%s | subtitle=%s | body=%s | time=%s",
          notif["app"], notif["title"], notif["subtitle"], notif["body"], ts_str,
      )

      # Webhook delivery (only if config with webhook_url)
      if config is not None and config.get("webhook_url"):
          msg_type = classify_notification(notif)
          payload = build_webhook_payload(notif, msg_type)
          post_webhook(
              payload,
              config["webhook_url"],
              config.get("webhook_timeout", 10),
          )
  ```
  Note: Keep the info-level notification log AFTER filtering but BEFORE webhook POST. This ensures the user sees what's being forwarded.

**Modify `main()`:**
- BEFORE the try block, add: `config = load_config()`
- After config load, set logging level from config: `logging.getLogger().setLevel(getattr(logging, config.get("log_level", "INFO").upper(), logging.INFO))`
- Change `run_watcher(db_path, wal_path, STATE_FILE)` to `run_watcher(db_path, wal_path, STATE_FILE, config)`

IMPORTANT: These modifications must preserve backward compatibility. If config is None, the event loop should behave exactly as Phase 1 (log-only mode). This ensures `python3 nchook.py` works even if config.json loading is bypassed for testing.
  </action>
  <verify>
```bash
# Verify the module still imports cleanly
python3 -c "
from nchook import main, run_watcher, print_startup_summary, load_config
import inspect

# Verify run_watcher accepts config parameter
sig = inspect.signature(run_watcher)
assert 'config' in sig.parameters, 'run_watcher missing config param'

# Verify print_startup_summary accepts config parameter
sig = inspect.signature(print_startup_summary)
assert 'config' in sig.parameters, 'print_startup_summary missing config param'

# Verify main references load_config
src = inspect.getsource(main)
assert 'load_config' in src, 'main() does not call load_config'
assert 'config' in src, 'main() does not use config'

# Verify run_watcher references the pipeline functions
src = inspect.getsource(run_watcher)
assert 'passes_filter' in src, 'run_watcher missing passes_filter call'
assert 'classify_notification' in src, 'run_watcher missing classify_notification call'
assert 'build_webhook_payload' in src, 'run_watcher missing build_webhook_payload call'
assert 'post_webhook' in src, 'run_watcher missing post_webhook call'
assert 'poll_interval' in src, 'run_watcher not using config poll_interval'

print('All integration wiring tests passed.')
"
```

```bash
# Verify config.json loads correctly with load_config
python3 -c "
import os
os.chdir(os.path.dirname(os.path.abspath('nchook.py')) or '.')
from nchook import load_config
config = load_config()
assert 'webhook_url' in config
assert isinstance(config['bundle_ids'], set)
assert 'poll_interval' in config
print('Config loads successfully:', {k: v for k, v in config.items() if k != 'webhook_url'})
print('webhook_url present:', bool(config.get('webhook_url')))
"
```
  </verify>
  <done>
The complete pipeline is wired: main() loads config, passes it to run_watcher(), which filters each notification through passes_filter(), classifies with classify_notification(), builds payload with build_webhook_payload(), and delivers with post_webhook(). Startup summary shows webhook URL and bundle IDs. Poll interval comes from config. Filtered notifications logged at DEBUG. The daemon is a complete Teams notification interceptor.

Requirements covered: WEBH-01 (POST to webhook), WEBH-02 (JSON payload fields), WEBH-03 (timeout with log-and-skip), DBWT-06 (subtitle in payload), CONF-01 (config file integration into startup and event loop).
  </done>
</task>

</tasks>

<verification>
- `python3 -c "from nchook import main"` succeeds
- run_watcher contains the complete pipeline: passes_filter -> classify_notification -> build_webhook_payload -> post_webhook
- main() calls load_config() before run_watcher()
- print_startup_summary shows webhook URL and bundle IDs when config is provided
- post_webhook never crashes on any failure type
- Filtered notifications logged at DEBUG level, passing notifications at INFO level
- All existing Phase 1 behavior preserved when config is None
</verification>

<success_criteria>
1. All integration wiring assertions pass (inspect-based verification)
2. Config file loads and is passed through the full call chain
3. The notification processing loop contains the filter-classify-build-post pipeline
4. Startup summary includes webhook URL and bundle IDs
5. `python3 nchook.py` starts without error (requires config.json with valid webhook_url -- will use the example file)
</success_criteria>

<output>
After completion, create `.planning/phases/02-teams-filtering-webhook-delivery/02-02-SUMMARY.md`
</output>
