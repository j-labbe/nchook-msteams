---
phase: 01-db-watcher-state-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - nchook.py
  - state.json
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "Startup detects the Sequoia+ notification DB path automatically"
    - "Startup fails with actionable FDA error when Full Disk Access is denied"
    - "Startup prints summary showing DB path, FDA status, and last rec_id"
    - "Binary plist blobs are decoded to extract app, title, subtitle, body, and timestamp"
    - "State file persists last_rec_id across process restarts using atomic writes"
    - "DB purge is detected when max rec_id < persisted rec_id, and state resets with warning"
  artifacts:
    - path: "nchook.py"
      provides: "Core daemon with startup validation, DB access, plist parsing, state management"
      contains: "def validate_environment"
    - path: "nchook.py"
      provides: "Binary plist decoding with nested req key access"
      contains: "def parse_notification"
    - path: "nchook.py"
      provides: "State persistence with atomic writes"
      contains: "def save_state"
    - path: "nchook.py"
      provides: "DB purge detection"
      contains: "def check_db_consistency"
    - path: ".gitignore"
      provides: "Excludes runtime artifacts"
      contains: "state.json"
  key_links:
    - from: "validate_environment"
      to: "sqlite3.connect with mode=ro URI"
      via: "FDA check by attempting DB read"
      pattern: "file:.*\\?mode=ro"
    - from: "parse_notification"
      to: "plist nested req key"
      via: "plistlib.loads + req.get"
      pattern: 'plist\.get\("req"'
    - from: "save_state"
      to: "os.replace for atomic write"
      via: "tempfile + fsync + replace"
      pattern: "os\\.replace"
    - from: "check_db_consistency"
      to: "SELECT MAX(rec_id)"
      via: "SQL comparison with persisted value"
      pattern: "MAX\\(rec_id\\)"
---

<objective>
Build the foundational nchook.py daemon module with startup validation, DB access, plist parsing, and state persistence -- everything except the event loop.

Purpose: This is the core engine that all subsequent work depends on. It must correctly detect the DB, validate FDA, parse notification blobs (including the nested `req` key structure), persist state atomically, and detect DB purges. Without these foundations, the event loop (Plan 02) has nothing to drive.

Output: A runnable `nchook.py` with importable functions for DB access, parsing, state management, and startup validation. A `.gitignore` that excludes runtime artifacts.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-db-watcher-state-engine/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create nchook.py with startup validation, DB access, and plist parsing</name>
  <files>nchook.py, .gitignore</files>
  <action>
Create `nchook.py` as a Python 3.12+ module (shebang: `#!/usr/bin/env python3`). Use ONLY stdlib modules -- no external dependencies.

**Imports needed:** `os`, `sys`, `sqlite3`, `plistlib`, `json`, `logging`, `tempfile`, `pathlib`, `time`, `select`, `signal`, `subprocess`, `argparse`.

**1. DB Path Detection (`detect_db_path()`):**
- Check Sequoia+ path first: `~/Library/Group Containers/group.com.apple.usernoted/db2/db`
- Fall back to legacy path via `getconf DARWIN_USER_DIR` + `com.apple.notificationcenter/db2/db`
- Return `(db_path, wal_path)` tuple where `wal_path = db_path + "-wal"`
- Exit with clear error if neither path exists, mentioning macOS Sequoia+ requirement

**2. FDA Validation + DB Open (`validate_environment(db_path)`):**
- Attempt `sqlite3.connect(f"file:{db_path}?mode=ro", uri=True, timeout=5.0)` with `row_factory = sqlite3.Row`
- On success: run `SELECT COUNT(*) FROM record` to verify actual read access
- On `OperationalError` with "unable to open database file" AND the file exists (checked via `os.path.exists`): print the specific FDA instructions (System Settings > Privacy & Security > Full Disk Access > add terminal app) and `sys.exit(1)`
- Verify schema: check that `record` and `app` tables exist via `sqlite_master` query. Exit with error if missing.
- Return the open connection on success

**3. Binary Plist Parsing (`parse_notification(raw_data)`):**
- CRITICAL: Fields are nested under `"req"` key. `titl`, `subt`, `body` are at `plist["req"]["key"]`. `app` and `date` are TOP LEVEL.
- Use `plistlib.loads(raw_data, fmt=plistlib.FMT_BINARY)`. If that fails, retry without `fmt` param (auto-detect).
- Return dict: `{"app": str, "title": str, "subtitle": str, "body": str, "timestamp": float}` where timestamp is Unix epoch (Cocoa + 978307200).
- Return `None` on any parse failure (don't crash).

**4. DB Query (`query_new_notifications(conn, last_rec_id)`):**
- SQL: `SELECT r.rec_id, r.data, a.identifier, r.delivered_date FROM record r JOIN app a ON r.app_id = a.app_id WHERE r.rec_id > ? ORDER BY r.rec_id ASC`
- For each row: call `parse_notification(row['data'])`. Skip (log warning) if returns None.
- Override `notif['app']` with `row['identifier']` from the JOIN (more reliable than plist app field).
- Set `notif['rec_id'] = row['rec_id']`.
- Return list of notification dicts.

**5. Startup Summary (`print_startup_summary(db_path, last_rec_id)`):**
- Print formatted banner with: DB path, FDA status (always "OK" at this point since validation passed), last rec_id.
- Use `logging.info` for the summary lines.

**6. Logging setup:**
- Configure at module level: `logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')`

**7. Create `.gitignore`:**
- Include: `state.json`, `__pycache__/`, `*.pyc`, `.DS_Store`

Do NOT add the event loop, main(), or kqueue watcher in this task -- that is Plan 02.
  </action>
  <verify>
Run `python3 -c "import nchook; print('imports OK')"` from the project root. It should print "imports OK" without any ImportError (no external dependencies).

Run `python3 -c "from nchook import detect_db_path, validate_environment, parse_notification, query_new_notifications, save_state, load_state, check_db_consistency, print_startup_summary; print('all functions exist')"` to verify all expected functions are exported.
  </verify>
  <done>
nchook.py exists with all 5 core functions implemented using only stdlib. .gitignore excludes state.json and __pycache__. Module imports cleanly without errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add state persistence and DB purge detection</name>
  <files>nchook.py</files>
  <action>
Add state management functions to `nchook.py`:

**1. State File Path:**
- Default `STATE_FILE = "state.json"` at module level (in project directory, same as config convention from PROJECT.md).

**2. `save_state(last_rec_id, state_path=STATE_FILE)`:**
- Write `{"last_rec_id": <int>}` to a temp file in the same directory as state_path
- Use `tempfile.NamedTemporaryFile(mode='w', dir=<same_dir>, suffix='.tmp', delete=False)`
- `json.dump()` the state, then `tmp.flush()`, then `os.fsync(tmp.fileno())`, then `os.replace(tmp_path, state_path)`
- This is the atomic write-then-replace pattern (POSIX atomic per Python docs)
- Wrap in try/except: log error but don't crash if state save fails

**3. `load_state(state_path=STATE_FILE)`:**
- Try to open and `json.load()` the state file
- Return `last_rec_id` value (int), defaulting to 0
- On `FileNotFoundError`, `json.JSONDecodeError`, or `KeyError`: return 0 (fresh start)

**4. `check_db_consistency(conn, persisted_rec_id)`:**
- Query `SELECT MAX(rec_id) FROM record`
- If max_rec_id is None (empty DB): return 0
- If `persisted_rec_id > max_rec_id`: log WARNING with both values ("DB purge detected: persisted rec_id=X > max DB rec_id=Y. Resetting state."), return 0
- Otherwise: return `persisted_rec_id` unchanged

**5. Integration point:**
- These functions should be called in sequence during startup: `load_state()` -> `check_db_consistency()` -> use resulting rec_id
- The save_state function should be called after processing each batch of notifications (not after each individual notification -- batch save is sufficient)

Ensure save_state and load_state round-trip correctly: `save_state(42)` then `load_state()` returns 42.
  </action>
  <verify>
Run a round-trip test from the command line:
```
python3 -c "
from nchook import save_state, load_state
import os
test_path = '/tmp/test_nchook_state.json'
save_state(12345, test_path)
result = load_state(test_path)
assert result == 12345, f'Expected 12345, got {result}'
os.unlink(test_path)
print('State round-trip OK')
"
```

Test load_state with missing file:
```
python3 -c "
from nchook import load_state
result = load_state('/tmp/nonexistent_state.json')
assert result == 0, f'Expected 0, got {result}'
print('Missing state file returns 0: OK')
"
```
  </verify>
  <done>
save_state atomically writes last_rec_id to JSON file using write-then-replace. load_state reads it back, returning 0 if missing/corrupt. check_db_consistency detects DB purge and resets. Round-trip test passes.
  </done>
</task>

</tasks>

<verification>
1. `python3 -c "import nchook"` succeeds with no errors
2. All core functions are importable: detect_db_path, validate_environment, parse_notification, query_new_notifications, save_state, load_state, check_db_consistency, print_startup_summary
3. State round-trip test passes (save 12345, load returns 12345)
4. Missing state file returns 0 (no crash)
5. .gitignore contains state.json and __pycache__
6. No external dependencies used (only stdlib imports)
</verification>

<success_criteria>
- nchook.py contains all foundational functions for the notification engine
- State persistence uses atomic write-then-replace pattern
- DB purge detection compares persisted rec_id against MAX(rec_id)
- Plist parsing accesses nested req key (not top-level) for titl/subt/body
- FDA validation provides actionable error message
- All functions can be verified without FDA (import + unit-level checks pass)
</success_criteria>

<output>
After completion, create `.planning/phases/01-db-watcher-state-engine/01-01-SUMMARY.md`
</output>
